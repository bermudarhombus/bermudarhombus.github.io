<!DOCTYPE html>
<html>

<head>
    <title>Tony Regli</title>
    <link rel="icon" type="image/png" href="images/favicon-32x32.png" sizes="32x32" />
    <link rel="icon" type="image/png" href="iamges/favicon-16x16.png" sizes="16x16" />
    <style>
        body {
            background-color: #c1e9ed;
        }

        </style>
</head>



<body>

    <style>
        .main1 {
            text-align: center;
        }
    </style>


    <center><img src="../images/headshot.jpg" alt="Face" width = "150"/></center>
    <h1><center>Tony Regli</center></h1>
    <p><center>Tony Regli is a sophomore studying aerospace engineering at the University of Maryland: College Park. His research interests include human factors engineering for flight and using computer vision and AI to control aerospace systems.</center></p>

    <h2><center>UMD Collective Dynamics and Control Laboratory</center></h2>
    <p><center>I'm currently working on using computer vision to provide real-time guidance and tracking information to allow 2 robotic fish to swim in formation, syncing their motion to give hydrodynamic benefits to the follower fish through a technique that real fish use called vortex phase matching. Vortex phase matching is something live fish in schools do, by positioning themselves precisely with respect to the other fish in their swarm, they're able to take advantage of the 
        vortexes coming off of the surrounding fish, reducing drag and therefore reducing energy spent to move a given distance. It's already been shown that this is possible for robotic fish (see Liang et al at the bottom of the page), so the challenge is getting the fish to actually move in the right formation. Using 2 fish held one behind the other, this requires not only knowing the distance from the front fish to the rear, but for the rear fish to know how fast the leader fish is
        flapping, along with a phase shift from a zero point in time of the leader's flapping so that the follower can synchronize its movement with the leader. We're using a monocular camera on the follower fish to do this, which is what my work has been on. I've been writing the computer vision software using OpenCV in Python to get these guidance parameters. I've already gotten the guidance data with the follower fish flapping on a duty cycle (alternating one second flapping, one second coasting and
        recording video), and I'm still working on having it work with the follower constantly flapping so that it doesn't have to coast at all.
    </center></p>


    <h1><center>Research Experience</center></h2>
    <center><img src="../images/bpp.jpg" alt="Bpp" width="150"/></center>
    <h2><center>Balloon Payload Program</center></h2>
    <p><center>Tony is a member of the Univeristy of Maryland Balloon Payload Program (BPP), a student-run club that launches high altitude weather balloons carrying various payloads. He is currently the project lead on a payload called PTERODACTYL, a sensor suite planned to launch during the October 2023 and April 2024 solar eclipse. Additionally, he helps out on the launchpad during launches with inflating the balloons from high-pressure helium tanks.</center></p>
        

</html>


<p><center>    
    <a href="sub/research.html">Projects</a>
</center></p>
<p><center>    
    <a href="sub/projects.html">Projects</a>
</center></p>